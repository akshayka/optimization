<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Convex Optimization &middot; Research Notebook
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/optimization/public/css/poole.css">
  <link rel="stylesheet" href="/optimization/public/css/syntax.css">
  <link rel="stylesheet" href="/optimization/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/optimization/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/optimization/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/optimization/atom.xml">

  <!-- Latex Macros -->
  <p hidden>
  $$
  \newcommand{\argmin}[2]{\underset{#1}{\operatorname{argmin}} {#2}}
  \newcommand{\dist}[2]{\operatorname{dist}(#1, #2)}
  \newcommand{\fix}[1]{\operatorname{Fix}#1}
  \newcommand{\pnorm}[2]{\left\lVert{#1}\right\rVert_{#2}}
  \newcommand{\norm}[1]{\left\lVert{#1}\right\rVert}
  \newcommand{\inner}[2]{\langle{#1}, {#2}\rangle}
  \newcommand{\optmin}[3]{
	\begin{align*}
	& \underset{#1}{\text{minimize}} & & #2 \\
	& \text{subject to} & & #3
	\end{align*}
  }
  \newcommand{\optmax}[3]{
	\begin{align*}
	& \underset{#1}{\text{maximize}} & & #2 \\
	& \text{subject to} & & #3
	\end{align*}
  }
  \newcommand{\optfind}[2]{
	\begin{align*}
	& {\text{find}} & & #1 \\
	& \text{subject to} & & #2
	\end{align*}
  }
  $$
  </p>


</head>

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
		"HTML-CSS": { availableFonts: ["TeX"] },
		 TeX: { equationNumbers: { autoNumber: "AMS" } },
	  });
	</script>
	<script type="text/javascript"
		src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>By Akshay Agrawal. Commenced Oct. 5, 2016. Advised by Stephen Boyd.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/optimization/">Home</a>

    

    
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/about/">About</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/daily-sketch/">Daily Sketch</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/lecture-notes/">Lecture Notes</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/papers/">Papers</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/tags/">Tags</a>
        
      
    
      
    
      
    
      
    
      
    
      
    

    <a class="sidebar-nav-item" href="https://github.com/akshayka/projection_methods">GitHub project</a>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2017. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <label for="sidebar-checkbox" class="sidebar-toggle"></label>

          <h3 class="masthead-title">
            <a href="/optimization/" title="Home">Convex Optimization</a>
            <small>Research Notebook</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2017/02/07/averaged-projections-experiments/">
        Accelerating von Neumann's Alternating Projections Algorithm for Convex Feasibility
      </a>
    </h1>
    <span class="post-date">07 Feb 2017</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#averaged-projections" class="tag">averaged-projections</a>]
	
	  [<a href="/optimization/tags#acceleration" class="tag">acceleration</a>]
	
	  [<a href="/optimization/tags#QPs" class="tag">QPs</a>]
	
	</div>
	<p><em>The code for my experiments and algorithm is hosted on
<a href="https://www.github.com/akshayka/projection_methods">github</a>.</em></p>

<p>My research focuses on accelerating the alternating projections algorithm
for finding a point in the intersection of convex sets. The algorithm,
due to Jon von Neumann, is beautifully simple: just
alternatingly project the iterate onto your convex sets until it converges
to an optimal point, where optimality is obtained if and only if the iterate
lies in the intersection of the convex sets.</p>

<p>Aside from aesthetics, I am interested in the work because it is practical:
<em>the majority of convex optimization problems can be reduced to solving this
problem.</em> As such, this method is relevant to control, finance, and
machine learning, to name but a few fields.</p>

<p>Under the guidance of <a href="http://stanford.edu/~boyd/">Professor Stephen Boyd</a>,
I have devised a class of
modifications to the alternating projections method that is provably correct.
These modifications are guaranteed to take at most the number of iterations
that the vanilla algorithm takes and, though I have not yet theoretically verified
this, should take many fewer in most cases. The trade-off is that our version
of the algorithm requires us to solve three projections per iteration instead
of two; that said, the extra projection can be computed extremely cheaply.</p>

<p>In this post, I motivate the problem by illustrating a shortcoming of
the alternating projections method (convergence rapidly slows down as
the iterates approach optimality). I then propose an algorithm that
takes inspiration from the alternating projections method and provably
converges to an optimal point in the intersection of the convex sets in
question; the high-level idea is to solve a small quadratic program after
each pair of projections. There is much work left to be done,
and I close by listing the tasks that remain.</p>

<h2 id="motivation">Motivation</h2>
<p>The appeal of the alternating projection algorithm lies in its simplicity. But,
like other first-order methods, its
convergence can be rather slow. Especially towards the tail end of the
algorithm, you’ll find that the iterate often bounces back and forth between
the convex sets without making much forward progress towards the intersection;
if you come from the deep learning community, you can think of this problem
as somewhat analogous to the vanishing gradient problem.</p>

<p>The problem is best illustrated through example. Below is a run of the alternating
projections algorithm where the goal is to find a point in the intersection
of two circles. The algorithm begins with an initial iterate at <script type="math/tex">(0, 10)</script>.</p>

<p><img src="/optimization/assets/20170207-ap_circle.png" style="max-height:100%; max-width:100%" /></p>

<p>Notice how the iterate makes good progress at first but then gets stuck
zigzagging between the two sets as it approaches the intersection. This
slow convergence makes the algorithm impractical in many problem domains,
especially where high accuracy is required.</p>

<p>So here’s the key question: Can we come up with a cheap modification to the
alternating projection algorithm that prevents the sequence of iterates from
degenerating into a zigzag trajectory?</p>

<h2 id="the-algorithm">The Algorithm</h2>

<p>For the remainder of this post, I will assume that the inputs to my
algorithm are an affine set <script type="math/tex">\mathcal{A}</script> and a convex cone <script type="math/tex">\mathcal{K}</script>.
This assumption is not really an important one – the algorithm is correct
so long as both sets are convex. But it turns out that almost all practical
convex optimization problems can be reduced to finding a point in the
intersection of an affine set and a convex cone, hence the assumption.
In full specificity, the problem set-up is:</p>

<p><strong>Input</strong>: An affine set <script type="math/tex">\mathcal{A}</script> and a convex cone <script type="math/tex">\mathcal{K}</script>.</p>

<p><strong>Goal</strong>: Find a point <script type="math/tex">x \in \mathcal{A} \cap \mathcal{K}</script>.</p>

<p>The initial iterate <script type="math/tex">z_0</script> may be chosen randomly. Let <script type="math/tex">\Pi_{\mathcal{A}}</script> be
the projection operator onto <script type="math/tex">\mathcal{A}</script> and let be <script type="math/tex">\Pi_\mathcal{K}</script> the
projection operator onto <script type="math/tex">\mathcal{K}</script>. Let <script type="math/tex">z_k</script> be the <script type="math/tex">k</script>-th iterate.
After the <script type="math/tex">k</script>-th step of the algorithm, perform the following updates:</p>

<script type="math/tex; mode=display">q_k = \Pi_{\mathcal{A}}(z_k),
\quad r_k = \Pi_{\mathcal{K}}(z_k),
\quad s_k = \frac{1}{2}(q_k + r_k).</script>

<p>In other words, <script type="math/tex">s_k</script> is the iterate that would be obtained by averaged
projections. (It is easy to show that averaged projections is equivalent to
alternating projections.) In order to accelerate convergence, before performing
the next averaged projection iteration, we will project <script type="math/tex">s_k</script> onto the
intersection of a number of halfspaces that contain
<script type="math/tex">\mathcal{A} \cap \mathcal{K}</script>. More concretely, let
<script type="math/tex">\tilde{A} = \{x \mid (z_k - q_k)^T(x - q_k) \leq 0\}</script> be the halfspace
containing <script type="math/tex">\mathcal{A}</script> and let
<script type="math/tex">\tilde{K} = \{x \mid (z_k - r_k)^T(x - r_k) \leq 0\}</script> be the halfspace containing
<script type="math/tex">\mathcal{K}</script>. After obtaining these halfspaces, we can generate the
next iterate by projecting <script type="math/tex">s_k</script> onto their intersection; that is,
<script type="math/tex">z_{k+1} = \Pi_{\tilde{A} \cap \tilde{K}}(s_k)</script>.</p>

<p>It is not hard to prove that the above algorithm converges to an optimal
solution of the feasibility problem; my previous post has a very rough
proof sketch. I will post a complete proof sometime later.</p>

<p>There are many tweaks to the above algorithm that preserve convergence and may
accelerate it; for example, we can choose to keep all the halfspaces
and project onto the intersection of <script type="math/tex">2k</script> halfspaces on the <script type="math/tex">k</script>-th
iteration. Empirical results I’ve run suggest that doing so accelerates
convergence. Doing so also increases the cost of each iteration, but I
suspect the overhead is not sufficient. For example, see
<a href="/optimization/2016/10/24/boyd/">this post</a>
in which I discuss how to solve the projection cheaply.</p>

<p>This algorithm improves upon the vanilla version in the two-dimensional case.
Below is a run of my algorithm on the problem we saw in the previous section.</p>

<p><img src="/optimization/assets/20170207-qp_circle.png" style="max-height:100%; max-width:100%" /></p>

<h2 id="results">Results</h2>
<p>The results of a toy experiment I’ve run are promising and are plotted below;
the x-axis is the iteration number and the y-axis is the distance from
the iterate to the intersection. Experiments were run on a 1000 dimensional affine space
and a 1000 dimensional second order cone. I compared the performance
of my algorithm, both when only two halfspaces are retained and when
all of the halfspaces are retained, with the alternating projections
algorithm and the state-of-the-art Dykstra’s algorithm. It is evident that
keeping more halfspaces helps, at least in this experiment. (You can
ignore the “ip (1.00)” label in the legend – it stands for
“include the next halfspace with probability 1.0” and is a remnant from
experiments with a randomized version of the algorithm.)</p>

<p><img src="/optimization/assets/20170207-avg-proj-exp.png" style="max-height:100%; max-width:100%" /></p>

<p>I also want to answer the question whether momentum updates may help prevent
the QP algorithm that projections onto pairs of halfspaces from encountering
the same problems that vanilla averaged projections encounters. I hypothesize
that momentum will help, and my results support my hypothesis.</p>

<p><img src="/optimization/assets/20170207-avg-proj-momentum-exp.png" style="max-height:100%; max-width:100%" /></p>

<h2 id="conclusion">Conclusion</h2>
<p>My work is preliminary but promising: the algorithm I presented
is but one example of an acceleration we can apply to the alternating projection
method. There are many other things we could try, and their justifications
fall out from the proof of my algorithm (I will post the proof soon!).</p>

<h2 id="future-work">Future Work</h2>
<p>There’s a ton of future work to be done. Here’s a partial list:</p>
<ul>
  <li>Analyze the algorithm’s rate of convergence.</li>
  <li>Attempt to do a cheap line search or plane search to even further accelerate
convergence.</li>
  <li>Run experiments on larger problems.</li>
  <li>Implement a production-quality version of my algorithm, roll it into SCS,
and evaluate it on Mark’s test suite.</li>
</ul>

<p>Unrelated to this work, I’m also helping Steven Diamond with the design and
implementation of CVXPY 1.0.</p>

	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2017/01/29/averaged-projections-pf-sketch/">
        Proof Sketch: Outer Approximation Acceleration of Averaged Projections
      </a>
    </h1>
    <span class="post-date">29 Jan 2017</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#averaged-projections" class="tag">averaged-projections</a>]
	
	  [<a href="/optimization/tags#proof" class="tag">proof</a>]
	
	  [<a href="/optimization/tags#QP" class="tag">QP</a>]
	
	  [<a href="/optimization/tags#acceleration" class="tag">acceleration</a>]
	
	</div>
	<p>A simple but potentially powerful acceleration scheme: perform averaged
projections and then solve a small QP in which you project the averaged
iterate onto the intersection of the halfspaces that the projection
nets you. It is not difficult to show that this algorithm converges
to an optimal solution. Below is a proof sketch.</p>

<p><img src="/optimization/assets/acc-avg-proj.jpg" style="max-height:100%; max-width:100%" /></p>


	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2017/01/23/key-steps-alt-proj-pf/">
        Key Steps in the Proof of Alternating Projections
      </a>
    </h1>
    <span class="post-date">23 Jan 2017</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#proof" class="tag">proof</a>]
	
	  [<a href="/optimization/tags#convergence" class="tag">convergence</a>]
	
	  [<a href="/optimization/tags#alternating-projections" class="tag">alternating-projections</a>]
	
	</div>
	<p>An analysis of the proof of Von Neumann’s alternating projections algorithm.</p>

<p><img src="/optimization/assets/key-steps-alt-proj-pf.jpg" style="max-height:100%; max-width:100%" /></p>


	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/12/07/ap-first-results/">
        First results for alternating projection acceleration
      </a>
    </h1>
    <span class="post-date">07 Dec 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#alternating-projections" class="tag">alternating-projections</a>]
	
	  [<a href="/optimization/tags#experiments" class="tag">experiments</a>]
	
	  [<a href="/optimization/tags#results" class="tag">results</a>]
	
	</div>
	<ol>
  <li>Plane search does not obey fejer monotonicity</li>
  <li>Surprisingly, initial evidence implies that the heavy ball method
only hurts. This is of course not a conclusion, but rather an anecdotal
observation.</li>
  <li>QP (mem == 2) + overprojection seems to work decently well. Is the QP
projection cheap? Probably. Closed form? Maybe.</li>
</ol>

<h2 id="the-baseline-algorithms">The baseline algorithms:</h2>
<ol>
  <li>Alternating projections</li>
  <li>Alternating projections with heavy-ball momentum</li>
</ol>

<h2 id="the-state-of-the-art">The state-of-the-art:</h2>
<ol>
  <li>Dykstra</li>
</ol>

<h2 id="what-did-i-try">What did I try?</h2>
<p>Problem set-up:</p>

<ul>
  <li>1500-dimensional variable</li>
  <li>Affine constraint with random matrix <script type="math/tex">A</script> \in <script type="math/tex">\mathbb{R}^{1000 \times 1500}</script>,
1% sparsity.</li>
  <li><script type="math/tex">% <![CDATA[
x = \begin{bmatrix}y & z\end{bmatrix} %]]></script>,
<script type="math/tex">y \in \mathbb{R}^{500}, z</script> constrained to be in the second-order cone.</li>
</ul>

<p>(1) A <strong>plane search</strong>:</p>

<script type="math/tex; mode=display">\optmin{\theta}{\dist{\sum_{i} \theta_i a_i}{\mathcal{C}}^2}{\sum_{i} \theta_i = 1, \quad \theta_i \in [0, 1],}</script>

<p><script type="math/tex">a_i</script> are a finite number of previous iterates that were on the affine set,
<script type="math/tex">\mathcal{C}</script> the convex cone. It turns out that performing this plane search produces
sequences that are <strong>not Fejer monotonic</strong>!</p>

<p>(2) <strong>Halfpsace Outer Approximation (HOA)</strong></p>

<p>I used the <script type="math/tex">k</script> most recent halfspaces generated by projecting onto the convex
sets, and obtained the next iterate by projecting onto the intersection of these
sets. This works “fairly well.” It works “better” than Dykstra’s if we only look
at the number of iterations. Of course, the number of iterations isn’t a “good”
metric, but it’s a start. Even small <script type="math/tex">k</script> (<script type="math/tex">k = 2</script>) works well.</p>

<p>(3) <strong>HOA with randomly accepting new hyperplanes.</strong></p>

<p>I don’t understand this well yet, but I suspect there is something interesting
here.</p>

<p>(4) <strong>HOA with momentum</strong></p>

<p>Anecdotally, momentum “helps” with respect to the number of iterations.
Over-projecting seems to be more useful than interpolating between the previous
velocity and the current one. Again, very anecdotal evidence.</p>

<h2 id="future-work-and-experiments">Future work and experiments</h2>
<p>(0) Write-up what I’ve done and learned this quarter and send it to Prof. Boyd.</p>

<p>(1) Anneal the momentum (say by a factor of <script type="math/tex">1/\sqrt{n}</script>,
    <script type="math/tex">n</script> the # of iterations)?</p>

<p>(2) Flip a p-biased coin to decide whether or not to oveproject</p>

<p>(3) Flip a p-biased coin and overproject by a lot</p>

<p>(4) Take advantage of short-and-fat matrix structure, if it arises</p>

<p>(5) Project onto random subsets of equality constraints</p>

<p>(6) Test on the homogeneous self-dual embedding of a cone program (SCS).</p>

<h2 id="questions-for-professor-boyd">Questions for Professor Boyd</h2>
<p>(1) Does a closed-form projector onto the intersection of two halfspaces
    exist, and/or can it be computed cheaply by some means?</p>

<p>(2) Why is the optimal value returned by CVXPY inaccurate?
   (roughly 10e-2 precision.)</p>

<p>(3) Lots of stuff I want to try empirically. If anything stands out,
    will go forward with theoretical analysis. HOA + momentum seems the
    most promising right now. Does that sound good?</p>

<p>(4) Logistics for continuing the work next quarter? Is an independent study
    still possible? I think I have sufficient momentum now to carry me forward.
    Will you be reachable by email? (If not, that’s totally understandable!)</p>

<p>(5) I’m still very much interested in TA-ing convex in the spring, if the offer
    still stands.</p>

	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/11/09/visual-checklist/">
        Checklist
      </a>
    </h1>
    <span class="post-date">09 Nov 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#checklist" class="tag">checklist</a>]
	
	  [<a href="/optimization/tags#framework" class="tag">framework</a>]
	
	  [<a href="/optimization/tags#models" class="tag">models</a>]
	
	  [<a href="/optimization/tags#algorithms" class="tag">algorithms</a>]
	
	</div>
	<h2 id="the-problems">1. The Problems.</h2>
<p>Each problem must eventually be cast as a feasibility problem. In particular,
the feasibility problem must be cast as finding a point in the intersection
of an affine set and a cone. Note that the cone, however, may be the
cross-product of multiple different cones.</p>

<h2 id="the-algorithms">2. + 3. The Algorithms</h2>

<p><script type="math/tex">\color{red}{[\text{Specification}]}\color{blue}{[\text{Implementation}]}</script>.</p>

<p><script type="math/tex">\color{red}{[\checkmark]}\color{blue}{[\checkmark]}</script> Alternating projections</p>

<p><script type="math/tex">\color{red}{[\checkmark]}\color{blue}{[\checkmark]}</script> Dykstra’s</p>

<p><script type="math/tex">\color{red}{[\checkmark]}\color{blue}{[\circ]}</script>  ADMM</p>

<p><script type="math/tex">\color{red}{[\checkmark]}\color{blue}{[\checkmark]}</script>
  Halfspace Eliminating Alternating Projections (memory <script type="math/tex">k = 2</script>)</p>

<p><script type="math/tex">\color{red}{[\checkmark]}\color{blue}{[\checkmark]}</script>
  Halfspace Eliminating Alternating Projections (memory <script type="math/tex">k > 2</script>)</p>

<p><script type="math/tex">\color{red}{[\checkmark]}\color{blue}{[\checkmark]}</script>
  Halfspace Eliminating Alternating Projections, with momentum</p>

<p><script type="math/tex">\color{red}{[\circ]}\color{blue}{[\circ]}</script>
  Halfspace Eliminating Alternating Projections, with plane search / momentum</p>

<p><script type="math/tex">\color{red}{[\circ]}\color{blue}{[\circ]}</script>
  Halfspace Eliminating Alternating Projections, with plane search / momentum
  and additional problem transformations</p>

<h2 id="theoretical-analyses">4. Theoretical Analyses</h2>
<p><script type="math/tex">{[\checkmark]}</script>
  Halfspace Eliminating Alternating Projections (free, from Pang)</p>

<p><script type="math/tex">{[\circ]}</script> Halfspace Eliminating Alternating Projections, with plane search</p>

<p><script type="math/tex">{[\circ]}</script> Halfspace Eliminating Alternating Projections, with plane search
  and additional problem transformations</p>

<h2 id="the-test-cases">5. The Test Cases</h2>
<p><script type="math/tex">[\checkmark]</script> 2D feasibility problems, for intuition’s sake.</p>

<p><script type="math/tex">[\checkmark]</script> Intersection of second-order cone and affine set,
  randomly generated</p>

<p><script type="math/tex">[\circ]</script> Random cone problems of varying sizes.</p>

<ul>
  <li>NB: Can use the method described in the long SCS paper to generate these
problems. Will need to take generated problem and form the self-dual
homogeneous embedding in order to recover the feasibility problem, however.</li>
</ul>

<p><script type="math/tex">[\circ]</script> Open test suite for feasibility problems?</p>
<ul>
  <li>To the best of my knowledge, none exist!</li>
</ul>

	
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/optimization/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>

      </div>
    </div>

  </body>
</html>
