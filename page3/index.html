<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Convex Optimization &middot; Research Notebook
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/optimization/public/css/poole.css">
  <link rel="stylesheet" href="/optimization/public/css/syntax.css">
  <link rel="stylesheet" href="/optimization/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/optimization/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/optimization/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/optimization/atom.xml">

  <!-- Latex Macros -->
  <p hidden>
  $$
  \newcommand{\argmin}[2]{\underset{#1}{\operatorname{argmin}} {#2}}
  \newcommand{\dist}[2]{\operatorname{dist}(#1, #2)}
  \newcommand{\fix}[1]{\operatorname{Fix}#1}
  \newcommand{\pnorm}[2]{\left\lVert{#1}\right\rVert_{#2}}
  \newcommand{\norm}[1]{\left\lVert{#1}\right\rVert}
  \newcommand{\inner}[2]{\langle{#1}, {#2}\rangle}
  \newcommand{\optmin}[3]{
	\begin{align*}
	& \underset{#1}{\text{minimize}} & & #2 \\
	& \text{subject to} & & #3
	\end{align*}
  }
  \newcommand{\optmax}[3]{
	\begin{align*}
	& \underset{#1}{\text{maximize}} & & #2 \\
	& \text{subject to} & & #3
	\end{align*}
  }
  \newcommand{\optfind}[2]{
	\begin{align*}
	& {\text{find}} & & #1 \\
	& \text{subject to} & & #2
	\end{align*}
  }
  $$
  </p>


</head>

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
		"HTML-CSS": { availableFonts: ["TeX"] },
		 TeX: { equationNumbers: { autoNumber: "AMS" } },
	  });
	</script>
	<script type="text/javascript"
		src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>By Akshay Agrawal. Commenced Oct. 5, 2016. Advised by Stephen Boyd.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/optimization/">Home</a>

    

    
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/about/">About</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/daily-sketch/">Daily Sketch</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/lecture-notes/">Lecture Notes</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/papers/">Papers</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/optimization/tags/">Tags</a>
        
      
    
      
    
      
    
      
    
      
    

    <a class="sidebar-nav-item" href="https://github.com/akshayka/optimization-notebook">GitHub project</a>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2017. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <label for="sidebar-checkbox" class="sidebar-toggle"></label>

          <h3 class="masthead-title">
            <a href="/optimization/" title="Home">Convex Optimization</a>
            <small>Research Notebook</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/10/20/speeding-up-alt-projections/">
        Speeding up Subgradient Methods & Alternating Projections
      </a>
    </h1>
    <span class="post-date">20 Oct 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#subgradients" class="tag">subgradients</a>]
	
	  [<a href="/optimization/tags#alternating-projections" class="tag">alternating-projections</a>]
	
	  [<a href="/optimization/tags#dykstra" class="tag">dykstra</a>]
	
	  [<a href="/optimization/tags#QP" class="tag">QP</a>]
	
	  [<a href="/optimization/tags#cones" class="tag">cones</a>]
	
	  [<a href="/optimization/tags#affine-sets" class="tag">affine-sets</a>]
	
	</div>
	<p>Plan of attack (not necessarily sequential):</p>
<ul>
  <li>Get up to speed with Boyd’s notes on subgradient methods + alternating
projections</li>
  <li>Skim Bertseka’s sections on subgradient methods</li>
  <li>Skim survey of speedup techniques for alternating projections
(under/overprojection, dyskstra)</li>
  <li>Skim ideas for QP-acceleration (Pang’s work)</li>
  <li>Contribute — propose acceleration techniques (non-rigorously at first!)</li>
  <li>QP “line search”</li>
  <li>random perturbations &amp; drift directions</li>
  <li>interpolating between new data and previous estimate</li>
  <li>sketch system of inequalities implied by collection of supporting
hyperplanes</li>
  <li>What additional structure do we gain / what structure do we lose by changing
one of the sets to a convex cone? (different types of cones – second order,
exponential, …)</li>
</ul>


	
		<a href="/optimization/2016/10/20/speeding-up-alt-projections/">Read more</a>
	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/10/17/research-directions/">
        Research Directions, Week 4
      </a>
    </h1>
    <span class="post-date">17 Oct 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#journal" class="tag">journal</a>]
	
	  [<a href="/optimization/tags#localization" class="tag">localization</a>]
	
	  [<a href="/optimization/tags#cutting-plane" class="tag">cutting-plane</a>]
	
	  [<a href="/optimization/tags#alternating-projections" class="tag">alternating-projections</a>]
	
	  [<a href="/optimization/tags#randomized" class="tag">randomized</a>]
	
	</div>
	<p>Until now, I’ve spent most of my time reviewing foundations and learning
about classic methods, including subgradient methods, proximal methods,
and localization methods.</p>

<p>I should begin playing with these methods. That is, I need to take a step
back (or rather, a step forward?) from the literature, and I need to begin
creating and contributing on my own.</p>

<p>There are two things that are immediate with which I would like to play. They
both fall under the category of variants on localization methods.</p>

<ol>
  <li>The first is a variant on the “line search” used in alternating projections,
where the sets <script type="math/tex">C</script> and <script type="math/tex">D</script> are affine and conical, respectively.  Can we
play with how the iterates are chosen? (Like under- and over-projection, for
example.) And will playing with these iterates speed up convergence?</li>
  <li>The second is a variant on the cutting plane method. Can we be smarter
about which cutting planes we keep and which ones we discard? Can randomness
help us? Can we “sketch” a convex function? Can we represent it in a
lower-dimensional space?</li>
</ol>

<p>A third project that I am interested in is applying randomized methods to
convex optimization or convex feasibility problems (or even to nonconvex
feasibility problems). Mert Pilanci does work in this area, and he is at
Stanford.</p>

	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/10/17/david-hallac/">
        David Hallac [10/17/2016]
      </a>
    </h1>
    <span class="post-date">17 Oct 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#hallac" class="tag">hallac</a>]
	
	  [<a href="/optimization/tags#scalable" class="tag">scalable</a>]
	
	</div>
	<p>Hallac specializes in methods for scalable optimization and
unsupervised learning (time series anomaly detection …).</p>

<ul>
  <li>An interesting idea: Can we find a way of marrying
first-order methods and second-order methods? A system
that tells you whether a first-order method would suffice
for your problem, or whether you require a second-order
method. A pseudo-first-order method that used approximate
Newton steps when required. Along the lines of randomization.</li>
  <li>Why don’t more people use convex optimization / cvxpy?
According to Hallac, there simply isn’t much awareness about
it. That’s why Boyd travels so often, preaching about DCP
/ cvxpy. Moreover, people don’t have sufficient mathematical
training.
*</li>
</ul>


	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/10/14/cones/">
        Cones [Foundations]
      </a>
    </h1>
    <span class="post-date">14 Oct 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#foundations" class="tag">foundations</a>]
	
	  [<a href="/optimization/tags#cones" class="tag">cones</a>]
	
	</div>
	<p><strong>Definition.</strong> A <strong>cone</strong> is a set <script type="math/tex">K</script> such that <script type="math/tex">x \in K
\implies \theta x \in K, \; \forall \theta \geq 0</script> <a href="/optimization/texts/Convex Optimization [Boyd].pdf">[BV04]</a></p>

<p><strong>Definition.</strong> A <strong>convex cone</strong> is a cone that is also convex:
<script type="math/tex">\theta x + (1 - \theta) y \in K</script> if <script type="math/tex">x, y \in K</script> and <script type="math/tex">\theta \geq 0</script>.</p>

<p>An immediate corollary is that <script type="math/tex">x + y \in K</script> whenever <script type="math/tex">x, y \in K</script>.</p>

<p>Why do we care about cones?</p>

<p>Cones are “among the simplest convex sets” – think of them as the analog of
subspaces in linear analysis for convex analysis <a href="/optimization/texts/Convex Analysis and Minimization Algorithms I.pdf">[HU91]</a>. Note that
a subspace is a convex cone, but a convex cone is not necessarily a subspace.
Indeed, the only thing that prevents a convex cone from being a subspace is
symmetry (it is not necessarily the case that <script type="math/tex">K = -K</script>).</p>

<p>A hierarchy is:</p>
<ul>
  <li>Subspaces <script type="math/tex">\subsetneq</script> Convex Cones <script type="math/tex">\subsetneq</script> Convex Sets</li>
  <li>Subspaces <script type="math/tex">\subsetneq</script> Convex Cones <script type="math/tex">\subsetneq</script> Cones</li>
  <li>(The leftmost item is the most restrictive, and the rightmost item is the
least restrictive.)</li>
</ul>

<p>On the other hand, Cones <script type="math/tex">\not\subset</script> Convex Sets. Neither category contains
the other.</p>

<p>Examples of convex cones</p>
<ul>
  <li>The <strong>norm cone</strong> associated with <script type="math/tex">\vert\vert \cdot \vert\vert</script> is
<script type="math/tex">\{(x, y) \; \mid \; \vert\vert x \vert\vert \leq t \}</script>
    <ul>
      <li>The <strong>second-order cone</strong> is the <script type="math/tex">\ell_2</script>-norm cone</li>
      <li>The <strong>positive-semidefinite cone</strong>
<script type="math/tex">\mathbf{S}^n_+ = \{ X \in \mathbf{S}^{n} \mid X \geq 0\}</script>.</li>
    </ul>
  </li>
</ul>

<p>A <strong>proper cone</strong> is a cone that is</p>
<ol>
  <li>convex</li>
  <li>closed</li>
  <li>solid (non-empty interior)</li>
  <li>pointed (<script type="math/tex">x \in K \implies -x \not\in K \text{ or } x = 0</script>)</li>
</ol>

<p>Another reason we care about cones is that we can use proper cones to define
<strong>generalized inequalities</strong>.</p>


	
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/optimization/2016/10/14/alternating-projections/">
        Alternating Projections
      </a>
    </h1>
    <span class="post-date">14 Oct 2016</span>
	<div class="post-date">
	
	  [<a href="/optimization/tags#alternating-projections" class="tag">alternating-projections</a>]
	
	  [<a href="/optimization/tags#projections" class="tag">projections</a>]
	
	  [<a href="/optimization/tags#cones" class="tag">cones</a>]
	
	  [<a href="/optimization/tags#dual-cones" class="tag">dual-cones</a>]
	
	  [<a href="/optimization/tags#polar-cones" class="tag">polar-cones</a>]
	
	</div>
	<h2 id="projections-onto-closed-convex-sets">Projections onto Closed Convex Sets</h2>
<p><script type="math/tex">\newcommand{\norm}[1]{\left\lVert{#1}\right\rVert}
\newcommand{\inner}[2]{\langle{#1}, {#2}\rangle}</script>A projection onto nonempty
closed convex set <script type="math/tex">C</script> is <em>unique</em> <a href="/optimization/texts/Convex Analysis and Minimization Algorithms I.pdf">[U91]</a>.</p>

<p><strong>Theorem 1.</strong> <script type="math/tex">y_x \in C</script> is the projection of <script type="math/tex">x</script> onto <script type="math/tex">C</script> iff</p>

<script type="math/tex; mode=display">\langle x - y_x, y - y_x \rangle \leq 0\; \forall y \in C.</script>

<p>The geometric interpretation of this is nice — the angle between
<script type="math/tex">x - y_x</script> and <script type="math/tex">y - y_x</script> is obtuse for any <script type="math/tex">y \in C</script>.</p>

<p><strong>Theorem 2.</strong> For convex <script type="math/tex">C</script>, <script type="math/tex">P_C</script> is <strong>nonexpansive</strong>: that is,</p>

<script type="math/tex; mode=display">\lVert P_C(x) - P_C(y) \rVert \leq \lVert x - y \rVert .</script>

<p><em>Proof.</em>
We prove that</p>

<script type="math/tex; mode=display">\lVert P_C(x) - P_C(y)\rVert^2 \leq \langle P_C(x) - P_C(y), x - y \rangle,</script>

<p>applying Cauchy-Schwarz to which will give the desired result. By theorem 1,</p>

<script type="math/tex; mode=display">\langle x - P_C(x), P_C(y) - P_C(x) \rangle \leq 0 \text{ (1)}</script>

<p>and</p>

<script type="math/tex; mode=display">\langle y - P_C(y), P_C(x) - P_C(y) \rangle \leq 0 \text{ (2)}.</script>

<p>Adding (2) to (1) proves the claim:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
&\inner{x - P_Cx}{P_C(y) - P_C(x)} + \inner{y - P_C(y)}{P_C(x) - P_C(y)} \leq 0 \\
&\iff  -\inner{x - P_C(x)}{P_C(x) - P_C(y)} + \inner{y - P_C(y)}{P_C(x) - P_C(y)} \leq 0 \\
&\iff  \inner{P_C(x) - P_C(y)}{y - x + P_C(x) - P_C(y)} \leq 0 \\
&\iff  \inner{P_C(x) - P_C(y)}{P_C(x) - P_C(y)} \leq 
  \inner{P_C(x) - P_C(y)}{x - y} \\
&\iff  \pnorm{P_C(x) - P_C(y)}{2}^2 \leq  \inner{P_C(x) - P_C(y)}{x - y}  \\
&\implies  \pnorm{P_C(x) - P_C(y)}{2} \leq  \pnorm{x - y}{2}  \\
\end{align*} %]]></script>

<p><em>Q.E.D.</em></p>

<p>If <script type="math/tex">C</script> is a subspace, then <script type="math/tex">\pnorm{P_C(x)}{2} = \pnorm{Q^Tx}{2}</script>
(<script type="math/tex">P_C = QQ^T</script> for some <script type="math/tex">Q</script> with orthonormal columns).</p>

<h2 id="projection-onto-a-closed-convex-cone">Projection onto a Closed Convex Cone</h2>
<p>Projecting onto closed convex cones is “nice”, in some sense – these
projections begin to look like projections onto subspaces.</p>

<p><strong>Definition.</strong> The <strong>polar cone</strong> <script type="math/tex">K^\circ</script> of a cone <script type="math/tex">K</script> is defined as</p>

<script type="math/tex; mode=display">K^\circ = \left\{s \mid s^Tx \leq 0 \; \forall x \in K\right\}</script>

<p><strong>Definition.</strong> The <strong>dual cone</strong> <script type="math/tex">K^*</script> is defined as <script type="math/tex">-K^\circ.</script></p>

<p>Why care about the polar (dual) cone?</p>
<ul>
  <li>The polar cone is always a closed convex cone.</li>
  <li><script type="math/tex">K</script> a subspace <script type="math/tex">\implies K^\circ = K^\bot</script></li>
  <li><strong>In this sense, the polar/dual cone generalizes the orthogonal complement</strong></li>
  <li><script type="math/tex">K^{\circ\circ}</script> is the closure of <script type="math/tex">K</script>.</li>
  <li><script type="math/tex">K' \subset K \implies (K')^\circ \supset K^\circ</script>.</li>
</ul>

<p><strong>Theorem.</strong> <script type="math/tex">K</script> a closed convex cone, then <script type="math/tex">y_x = P_K(x)</script> iff the
following properties hold:</p>
<ol>
  <li><script type="math/tex">y_x \in K</script>,</li>
  <li><script type="math/tex">\; x-y_x \in K^\circ</script>,</li>
  <li><script type="math/tex">\langle x - y_x, y_x \rangle = 0</script>.</li>
</ol>

<p><strong>Corollaries.</strong></p>
<ol>
  <li><script type="math/tex">P_K(x) = 0 \iff x \in K^\circ</script>,</li>
  <li><script type="math/tex">P_K(\alpha x) = \alpha P_K(x) \; \forall \alpha \geq 0</script>,</li>
  <li><script type="math/tex">P_K(-x) = -p_{-K}(x)</script>.</li>
  <li><script type="math/tex">x = P_K(x) + P_{K^\circ}(x)</script>.</li>
</ol>

<p><em>Proof of 4.</em>
We want to show that</p>

<script type="math/tex; mode=display">y \in K,\; z \in K^\circ,\; x=y+z,\; \inner{y}{z}=0 \implies y=P_K(x), z=P_{K^\circ}(x).</script>

<p>First observe that <script type="math/tex">\forall q \in K, \; \inner{x-y}{q-y} = \inner{z}{q-y} =
\inner{z}{q} \leq 0</script>, where the last equality comes from the definition of the
polar cone. So <script type="math/tex">y</script> is the projection of <script type="math/tex">x</script> onto <script type="math/tex">K</script>.</p>

<p>Next observe that <script type="math/tex">\forall q \in K^\circ,\; \inner{x-z}{q-z} = \inner{y}{q-z}
= \inner{y}{q} \leq 0</script>, where again the last equality comes from the
definition of the polar cone. So <script type="math/tex">z = x - P_K(x) = P_{K^\circ}(x)</script>.</p>

<h2 id="alternating-projections-method">Alternating Projections Method</h2>

<p><strong>Goal</strong>: Find a point in the intersection of some closed convex sets <script type="math/tex">C</script> and
<script type="math/tex">D</script>, given <script type="math/tex">x_0 \in C</script>.</p>

<p><strong>Algorithm</strong>: Alternately project onto each set:</p>

<script type="math/tex; mode=display">y_k = P_D(x_k), \quad x_{k+1} = P_C(y_k), \quad k=0, 1, 2</script>

<p><strong>Caveat</strong>: Can be slow, but can be sped up when projections are easy to compute.
<strong>Theorem [CG59]</strong>: If <script type="math/tex">C \cap D \neq \emptyset</script>, then
<script type="math/tex">\lim x_k = \lim y_k = x^* \in C \cap D</script>.</p>

<p><em>Proof.</em></p>

<p>Let <script type="math/tex">\bar{x}</script> be any point in the intersection. Note that</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\lVert x_k - \bar{x} \rVert ^2 &= \lVert x_k - y_k + y_k - \bar{x} \rVert^2 \\
&= \lVert x_k - y_k \rVert^2 + \lVert y_k - \bar{x} \rVert^2 + 2(x_k - y_k)^T(y_k - \bar{x}) \\
&\geq \lVert x_k - y_k \rVert^2 + \lVert y_k - \bar{x} \rVert^2,
\end{align*} %]]></script>

<p>where the inequality comes from theorem 1. We can then see that</p>

<script type="math/tex; mode=display">\lVert y_k - \bar{x} \rVert^2
\leq \lVert x_k - \bar{x} \rVert^2 - \lVert y_k - x_k \rVert^2 \quad (3.1)</script>

<p>and, similarly,</p>

<script type="math/tex; mode=display">\lVert x_{k+1} - \bar{x} \rVert^2 \leq
\lVert y_k - \bar{x} \rVert^2 - \lVert x_{k+1} - y_k \rVert^2 \quad (3.2).</script>

<p>which imply that (1) <script type="math/tex">y_k</script> is closer to <script type="math/tex">\bar{x}</script> than <script type="math/tex">x_k</script> is, (2)
<script type="math/tex">x_{k+1}</script> is closer still to <script type="math/tex">\bar{x}</script>, and (3)
<script type="math/tex">\lVert y_k - \bar{x} \rVert</script> and <script type="math/tex">\lVert x_{k+1} - \bar{x} \rVert</script>
are both <script type="math/tex">\leq \lVert x_0 - \bar{x} \rVert</script>.</p>

<p>In particular, <script type="math/tex">\{x_k\}</script> is a bounded sequence and thus has a subsequence
that converges to some limit, call it  <script type="math/tex">x^*</script>. Since <script type="math/tex">C</script> is closed by
assumption, <script type="math/tex">x^* \in C</script>. It remains to be shown that <script type="math/tex">x^*</script> is in <script type="math/tex">D</script>.
Consider the sequence</p>

<script type="math/tex; mode=display">\norm{x_0 - \bar{x}},\; \norm{y_0 - \bar{x}},\; \norm{x_1 - \bar{x}},\;
\norm{y_1 - \bar{x}}, … \quad (3.3)</script>

<p>By (3.1) and (3.2), we see that (3.3) is decreasing but that it is also bounded.
That is, we see that (3.3) is convergent. Referencing (3.1) and (3.2), we see
that <script type="math/tex">\norm{y_k - x_k}</script> and <script type="math/tex">\norm{x_{k+1} - y_k}</script> must converge to <script type="math/tex">0</script>.
But since a subsequence of <script type="math/tex">\{x_k\}</script> goes to <script type="math/tex">x^*</script>, a
subsequence of <script type="math/tex">\{y_k\}</script> must do the same, and we can conclude that
<script type="math/tex">x^* \in D</script> as well. (I’m not sure if the previous sentence is correct;
it should probably instead argue that <script type="math/tex">\pnorm{x_k - y_k}{2} \rightarrow 0</script>
together with the fact that a subsequence of <script type="math/tex">\{x_k\} \rightarrow x^*</script>
implies that <script type="math/tex">x^* \in D</script> because each <script type="math/tex">y_k \in D</script>.)</p>

<p>Finally, let <script type="math/tex">\bar{x} = x^*</script>. A subsequence of <script type="math/tex">x</script> goes to <script type="math/tex">x^*</script>, as does
one of <script type="math/tex">y</script>. Since (3.3) converges, we conclude that <script type="math/tex">(3.3)</script> goes to zero
and in particular that <script type="math/tex">\{x_k\}</script> and <script type="math/tex">\{y_k\}</script> both converge to <script type="math/tex">x^*</script>.
<em>Q.E.D.</em></p>


	
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/optimization/page4">Older</a>
  
  
    
      <a class="pagination-item newer" href="/optimization/page2">Newer</a>
    
  
</div>

      </div>
    </div>

  </body>
</html>
